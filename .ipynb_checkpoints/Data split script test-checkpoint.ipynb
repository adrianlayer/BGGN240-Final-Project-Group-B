{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17d4f317-2630-465d-92c0-5bb636dff21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7729e240-dfa3-42dd-8dbd-7f4d95c59bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non PD Patients: 6934 train, 1486 val, 1487 test\n",
      "PD Patients: 21422 train, 4590 val, 4592 test\n"
     ]
    }
   ],
   "source": [
    "#We need to separate our images into training, testing, and validation groups\n",
    "#This can be accomplished by randomly selecting images from each patient group \n",
    "\n",
    "#Define the image splitting function\n",
    "#This takes in two directories, one with the image sources (root_dir) and \n",
    "#one where the split images are saved (output_dir)\n",
    "def split_images(root_dir, output_dir, splits=(0.7, 0.15, 0.15)):\n",
    "    categories = ['Non PD Patients', 'PD Patients']\n",
    "    # Set file paths\n",
    "    for category in categories:\n",
    "        category_path = os.path.join(root_dir, category)\n",
    "        output_category_path = os.path.join(output_dir, category)\n",
    "        os.makedirs(output_category_path, exist_ok=True)\n",
    "        \n",
    "        all_images = []\n",
    "        for patient_folder in os.listdir(category_path):\n",
    "            patient_path = os.path.join(category_path, patient_folder)\n",
    "            if os.path.isdir(patient_path):\n",
    "                mri_path = os.path.join(patient_path, '1.MRI')  # Select only MRI scans\n",
    "                if os.path.exists(mri_path):\n",
    "                    images = [os.path.join(mri_path, img) for img in os.listdir(mri_path) if img.endswith('.png')]\n",
    "                    all_images.extend(images)\n",
    "        \n",
    "        random.shuffle(all_images)\n",
    "        \n",
    "        split1 = int(splits[0] * len(all_images))\n",
    "        split2 = split1 + int(splits[1] * len(all_images))\n",
    "        \n",
    "        train_set = all_images[:split1]\n",
    "        val_set = all_images[split1:split2]\n",
    "        test_set = all_images[split2:]\n",
    "        \n",
    "        for split_name, split_data in zip(['train', 'val', 'test'], [train_set, val_set, test_set]):\n",
    "            split_path = os.path.join(output_category_path, split_name)\n",
    "            os.makedirs(split_path, exist_ok=True)\n",
    "            \n",
    "            for img_path in split_data:\n",
    "                shutil.copy(img_path, os.path.join(split_path, os.path.basename(img_path)))\n",
    "                \n",
    "        print(f\"{category}: {len(train_set)} train, {len(val_set)} val, {len(test_set)} test\")\n",
    "\n",
    "\n",
    "# set paths\n",
    "root_directory = r\"C:\\Users\\sirmo\\Desktop\\BGGN240 Final project\\ntua-parkinson-dataset-master\"  # Replace with the root directory containing dataset\n",
    "output_directory = r\"C:\\Users\\sirmo\\Desktop\\BGGN240 Final project\\split_dataset\"  # Output directory for the split data\n",
    "\n",
    "#run function\n",
    "split_images(root_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8456093-cb0f-4db7-97ea-ea7315971b03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
